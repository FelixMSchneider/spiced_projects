{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7861ab6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data analysis stack\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# data visualization stack\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# miscellaneous\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "# deep learning stack\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "#from tensorflow.keras import Model\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8537f76",
   "metadata": {},
   "source": [
    "#### Load pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e90b233a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Shoes', 'Spoons', 'Books', 'Forks']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "CLASSES = os.listdir('./data/Trainimages')\n",
    "CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce834b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 39 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "# define an image data generator\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "data_gen = keras.preprocessing.image.ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "# a generator that returns batches of x and y arrays\n",
    "test_data_gen = data_gen.flow_from_directory(\n",
    "        directory='./data/Testimages//',\n",
    "        class_mode=\"categorical\",\n",
    "        classes=CLASSES,\n",
    "        target_size=(224, 224)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0da4277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32, 224, 224, 3), (32, 4))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load in all images at once\n",
    "xtest, ytest = next(test_data_gen)\n",
    "xtest.shape, ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2a3822",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_learning_prediction(model,x,y):\n",
    "    \"\"\"\n",
    "    This function returns a dataframe with class probabilities\n",
    "    along with true class label \n",
    "    \"\"\"\n",
    "    # convert vectorized classes into strings\n",
    "    y = [''.join([i*j for (i,j) in zip(CLASSES,vector)]) for vector in y.astype(int)]\n",
    "    # prediction dataframe along with true class\n",
    "    prediction_df = pd.DataFrame(\n",
    "        columns=CLASSES,\n",
    "        data=np.round(model.predict(x,verbose=0),3)\n",
    "    )\n",
    "    prediction_df['class'] = y\n",
    "    return prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ad31e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "model = keras.models.load_model('my_model.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67133ca",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a71e0e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    }
   ],
   "source": [
    "pred=model.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26bda8c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.9999225e-01 5.6890281e-06 1.5013621e-06 4.5176671e-07]\n",
      " [3.6771577e-03 6.4630392e-03 7.7504271e-01 2.1481715e-01]\n",
      " [9.9998677e-01 6.0476527e-06 7.1852996e-06 6.2443696e-08]\n",
      " [1.8904531e-04 2.5524662e-04 9.8016709e-01 1.9388592e-02]\n",
      " [5.6362613e-05 9.4115370e-05 9.9954164e-01 3.0791687e-04]\n",
      " [1.3483737e-09 4.9252209e-04 2.4788471e-09 9.9950743e-01]\n",
      " [9.9989963e-01 5.1493935e-05 3.9833689e-05 9.0602962e-06]\n",
      " [1.2201895e-10 9.9998903e-01 1.2205493e-08 1.0910879e-05]\n",
      " [9.9672616e-01 3.1983552e-03 4.9511495e-05 2.5869989e-05]\n",
      " [2.7904434e-05 5.9980625e-01 8.0160771e-06 4.0015790e-01]\n",
      " [7.0552790e-04 7.8328165e-05 1.6835564e-01 8.3086056e-01]\n",
      " [2.1138375e-07 9.9964356e-01 4.6818236e-08 3.5624712e-04]\n",
      " [9.9958009e-01 7.3122465e-05 2.9248762e-04 5.4208842e-05]\n",
      " [1.4858458e-08 1.8446376e-07 2.5907812e-11 9.9999976e-01]\n",
      " [2.3149778e-03 8.1350678e-01 1.4801705e-02 1.6937660e-01]\n",
      " [3.4865441e-10 9.9999750e-01 3.6041292e-09 2.5336815e-06]\n",
      " [5.4566594e-06 9.9959904e-01 5.7685634e-07 3.9486185e-04]\n",
      " [9.9089187e-01 4.7803034e-08 9.1074929e-03 6.7547620e-07]\n",
      " [1.6902013e-07 1.5932799e-06 1.0021285e-09 9.9999833e-01]\n",
      " [3.3681763e-06 9.5574212e-01 6.4662265e-05 4.4189870e-02]\n",
      " [5.6362059e-03 1.4750906e-02 9.2333066e-01 5.6282215e-02]\n",
      " [3.8979101e-07 1.4736305e-03 1.1312361e-06 9.9852484e-01]\n",
      " [2.3870067e-05 1.1494827e-03 9.9882561e-01 1.0599164e-06]\n",
      " [7.9727088e-06 4.9932596e-01 2.8411198e-06 5.0066322e-01]\n",
      " [9.9961048e-01 2.7907112e-05 3.6104140e-04 5.2325038e-07]\n",
      " [2.6856276e-01 7.2689003e-01 7.8620430e-04 3.7610531e-03]\n",
      " [2.1767137e-06 3.6119815e-04 1.4790321e-07 9.9963641e-01]\n",
      " [3.5837544e-07 4.8986595e-04 1.9948803e-07 9.9950957e-01]\n",
      " [1.1236238e-05 4.0392693e-05 9.9986041e-01 8.7919012e-05]\n",
      " [4.1973191e-01 2.7710219e-05 5.8008689e-01 1.5351968e-04]\n",
      " [1.3520719e-06 9.3094909e-01 6.0059023e-07 6.9048956e-02]\n",
      " [3.1951433e-08 9.9969459e-01 2.4085687e-06 3.0309867e-04]]\n"
     ]
    }
   ],
   "source": [
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "309f1ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind=np.argmax(pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "569af0e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Shoes'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLASSES[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b8889dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 0, 2, 2, 3, 0, 1, 0, 1, 3, 1, 0, 3, 1, 1, 1, 0, 3, 1, 2, 3,\n",
       "       2, 3, 0, 1, 3, 3, 2, 2, 1, 1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(np.array(pred), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561c6f50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
